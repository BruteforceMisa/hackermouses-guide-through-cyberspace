<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>AI: Deep Learning | A HackerMouse’s Guide through Cyberspace</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="AI: Deep Learning" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="By now, you probably have the feeling why the terminology of neural networks and deep learning is used interchangeably. In fact, the neural network is “learning” the decision boundary based on how many datapoints are classified correctly and how many are classified incorrectly. This is done in two steps: the forward pass and the backpropagation step. In the forward pass, the neural network classifies all datapoints given its features. In the backpropagation step, we check how many datapoints are classified correctly. At one point in time, it is not possible to classify more datapoints correctly than we already have: this is our optimum. But how do we build such a network? A neural network consists of nodes/neurons which are organised in layers. A neural network consists of one input layer, several hidden layers and one output layer. The amount of nodes chosen for the network depends on your dataset. For our coffee &amp; tea dataset, we would define our network as follows: We have three input features, thus we choose three input neurons. Each input neuron is then used to model a feature. The hidden layer we can choose ourselves, depending on the chosen complexity of the model. As we want to classify whether our drink is coffee or tea, we have two output classes. Our output layer consists of two nodes. Our output neurons will model our output classes by using probabilities. Thus, the first output node would denote the probability that our drink is tea, and the second output node would denote the probability that our drink is coffee. Thus, the sum of our output neurons should be approximately 1. To train this network, we feed our first datapoint and label to our network. The network decides which of the features are more important to classify our drink, and which are less important. The weights between the nodes are updated accordingly. Based on the loss - i.e. how many datapoints are classified correctly - the network is adapted. Then, we put our second datapoint and label into the network. This sequence repeats until all datapoints are seen by the network. It is also possible to show the dataset another time to the network, in case the network has not found an optimum yet. Epoch is the term used in the deep learning community to indicate how many times the whole dataset is passed through the network. Keywords Backpropagation step - the step in the learning algorithm where mistakes are corrected by updating the weights Epoch - terminology for how often the dataset is passed through the network Forward pass - the step in the learning algorithm where datapoints are classified Loss - metric for the amount of mistakes made by the network. This is the function being minimalised Neuron- a basic computational unit within a neural network. Information flows through neurons and are multiplied by its weights depending on information importance Node - same as neuron Weights - the factor on how important a certain connection is between neurons. Used to give important features/nodes more power in the network and vice versa" />
<meta property="og:description" content="By now, you probably have the feeling why the terminology of neural networks and deep learning is used interchangeably. In fact, the neural network is “learning” the decision boundary based on how many datapoints are classified correctly and how many are classified incorrectly. This is done in two steps: the forward pass and the backpropagation step. In the forward pass, the neural network classifies all datapoints given its features. In the backpropagation step, we check how many datapoints are classified correctly. At one point in time, it is not possible to classify more datapoints correctly than we already have: this is our optimum. But how do we build such a network? A neural network consists of nodes/neurons which are organised in layers. A neural network consists of one input layer, several hidden layers and one output layer. The amount of nodes chosen for the network depends on your dataset. For our coffee &amp; tea dataset, we would define our network as follows: We have three input features, thus we choose three input neurons. Each input neuron is then used to model a feature. The hidden layer we can choose ourselves, depending on the chosen complexity of the model. As we want to classify whether our drink is coffee or tea, we have two output classes. Our output layer consists of two nodes. Our output neurons will model our output classes by using probabilities. Thus, the first output node would denote the probability that our drink is tea, and the second output node would denote the probability that our drink is coffee. Thus, the sum of our output neurons should be approximately 1. To train this network, we feed our first datapoint and label to our network. The network decides which of the features are more important to classify our drink, and which are less important. The weights between the nodes are updated accordingly. Based on the loss - i.e. how many datapoints are classified correctly - the network is adapted. Then, we put our second datapoint and label into the network. This sequence repeats until all datapoints are seen by the network. It is also possible to show the dataset another time to the network, in case the network has not found an optimum yet. Epoch is the term used in the deep learning community to indicate how many times the whole dataset is passed through the network. Keywords Backpropagation step - the step in the learning algorithm where mistakes are corrected by updating the weights Epoch - terminology for how often the dataset is passed through the network Forward pass - the step in the learning algorithm where datapoints are classified Loss - metric for the amount of mistakes made by the network. This is the function being minimalised Neuron- a basic computational unit within a neural network. Information flows through neurons and are multiplied by its weights depending on information importance Node - same as neuron Weights - the factor on how important a certain connection is between neurons. Used to give important features/nodes more power in the network and vice versa" />
<link rel="canonical" href="http://localhost:4000/hackermouses-guide-through-cyberspace/ai/2024/11/06/Deep-Learning.html" />
<meta property="og:url" content="http://localhost:4000/hackermouses-guide-through-cyberspace/ai/2024/11/06/Deep-Learning.html" />
<meta property="og:site_name" content="A HackerMouse’s Guide through Cyberspace" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-11-06T11:47:02+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="AI: Deep Learning" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-11-06T11:47:02+01:00","datePublished":"2024-11-06T11:47:02+01:00","description":"By now, you probably have the feeling why the terminology of neural networks and deep learning is used interchangeably. In fact, the neural network is “learning” the decision boundary based on how many datapoints are classified correctly and how many are classified incorrectly. This is done in two steps: the forward pass and the backpropagation step. In the forward pass, the neural network classifies all datapoints given its features. In the backpropagation step, we check how many datapoints are classified correctly. At one point in time, it is not possible to classify more datapoints correctly than we already have: this is our optimum. But how do we build such a network? A neural network consists of nodes/neurons which are organised in layers. A neural network consists of one input layer, several hidden layers and one output layer. The amount of nodes chosen for the network depends on your dataset. For our coffee &amp; tea dataset, we would define our network as follows: We have three input features, thus we choose three input neurons. Each input neuron is then used to model a feature. The hidden layer we can choose ourselves, depending on the chosen complexity of the model. As we want to classify whether our drink is coffee or tea, we have two output classes. Our output layer consists of two nodes. Our output neurons will model our output classes by using probabilities. Thus, the first output node would denote the probability that our drink is tea, and the second output node would denote the probability that our drink is coffee. Thus, the sum of our output neurons should be approximately 1. To train this network, we feed our first datapoint and label to our network. The network decides which of the features are more important to classify our drink, and which are less important. The weights between the nodes are updated accordingly. Based on the loss - i.e. how many datapoints are classified correctly - the network is adapted. Then, we put our second datapoint and label into the network. This sequence repeats until all datapoints are seen by the network. It is also possible to show the dataset another time to the network, in case the network has not found an optimum yet. Epoch is the term used in the deep learning community to indicate how many times the whole dataset is passed through the network. Keywords Backpropagation step - the step in the learning algorithm where mistakes are corrected by updating the weights Epoch - terminology for how often the dataset is passed through the network Forward pass - the step in the learning algorithm where datapoints are classified Loss - metric for the amount of mistakes made by the network. This is the function being minimalised Neuron- a basic computational unit within a neural network. Information flows through neurons and are multiplied by its weights depending on information importance Node - same as neuron Weights - the factor on how important a certain connection is between neurons. Used to give important features/nodes more power in the network and vice versa","headline":"AI: Deep Learning","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/hackermouses-guide-through-cyberspace/ai/2024/11/06/Deep-Learning.html"},"url":"http://localhost:4000/hackermouses-guide-through-cyberspace/ai/2024/11/06/Deep-Learning.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/hackermouses-guide-through-cyberspace/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/hackermouses-guide-through-cyberspace/feed.xml" title="A HackerMouse&apos;s Guide through Cyberspace" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/hackermouses-guide-through-cyberspace/">A HackerMouse&#39;s Guide through Cyberspace</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/hackermouses-guide-through-cyberspace/about/">About BruteforceMisa</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">AI: Deep Learning</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2024-11-06T11:47:02+01:00" itemprop="datePublished">Nov 6, 2024
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>By now, you probably have the feeling why the terminology of neural networks and deep learning is used interchangeably. In fact, the neural network is “learning” the decision boundary based on how many datapoints are classified correctly and how many are classified incorrectly. This is done in two steps: the <i>forward pass</i> and the <i>backpropagation step</i>. In the forward pass, the neural network classifies all datapoints given its features. In the backpropagation step, we check how many datapoints are classified correctly. At one point in time, it is not possible to classify more datapoints correctly than we already have: this is our optimum.</p>

<p>But how do we build such a network? A neural network consists of <i>nodes/neurons</i> which are organised in layers. A neural network consists of one input layer, several hidden layers and one output layer. The amount of nodes chosen for the network depends on your dataset. For our coffee &amp; tea dataset, we would define our network as follows:</p>

<p><img src="https://bruteforcemisa.github.io/hackermouses-guide-through-cyberspace/assets/images/DNN.png" alt="image" /></p>

<p>We have three input features, thus we choose three input neurons. Each input neuron is then used to model a feature. The hidden layer we can choose ourselves, depending on the chosen complexity of the model. As we want to classify whether our drink is coffee or tea, we have two output classes. Our output layer consists of two nodes. Our output neurons will model our output classes by using probabilities. Thus, the first output node would denote the probability that our drink is tea, and the second output node would denote the probability that our drink is coffee. Thus, the sum of our output neurons should be approximately 1.</p>

<p><img src="https://bruteforcemisa.github.io/hackermouses-guide-through-cyberspace/assets/images/DNNtraining.png" alt="image" /></p>

<p>To train this network, we feed our first datapoint and label to our network. The network decides which of the features are more important to classify our drink, and which are less important. The <i>weights</i> between the nodes are updated accordingly. Based on the <i>loss</i> - i.e. how many datapoints are classified correctly - the network is adapted. Then, we put our second datapoint and label into the network. This sequence repeats until all datapoints are seen by the network.</p>

<p>It is also possible to show the dataset another time to the network, in case the network has not found an optimum yet. <i>Epoch</i> is the term used in the deep learning community to indicate how many times the whole dataset is passed through the network.</p>

<p><b>Keywords</b></p>
<ul>
<li>Backpropagation step - the step in the learning algorithm where mistakes are corrected by updating the weights</li>
<li>Epoch - terminology for how often the dataset is passed through the network  </li>
<li>Forward pass - the step in the learning algorithm where datapoints are classified </li>
<li>Loss - metric for the amount of mistakes made by the network. This is the function being minimalised  </li>
<li>Neuron- a basic computational unit within a neural network. Information flows through neurons and are multiplied by its weights depending on information importance </li>
<li>Node - same as neuron</li>
<li>Weights - the factor on how important a certain connection is between neurons. Used to give important features/nodes more power in the network and vice versa</li>
</ul>

  </div><a class="u-url" href="/hackermouses-guide-through-cyberspace/ai/2024/11/06/Deep-Learning.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/hackermouses-guide-through-cyberspace/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">A HackerMouse&#39;s Guide through Cyberspace</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">A HackerMouse&#39;s Guide through Cyberspace</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/BruteforceMisa"><svg class="svg-icon"><use xlink:href="/hackermouses-guide-through-cyberspace/assets/minima-social-icons.svg#github"></use></svg> <span class="username">BruteforceMisa</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Concepts in the field of cyber security, cryptography and artificial intelligence explained inuitively.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
